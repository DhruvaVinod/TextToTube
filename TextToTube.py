import cv2
import easyocr
import json
import numpy as np
import os
import requests
import webbrowser
import yt_dlp
import googleapiclient.discovery
import re
import tempfile
import pygame

from gtts import gTTS
from faster_whisper import WhisperModel
from sentence_transformers import SentenceTransformer
import gradio as gr
import time
from deep_translator import GoogleTranslator, exceptions as dt_exceptions

pygame.mixer.init()

# API Keys
YOUTUBE_API_KEY = "AIzaSyD6hKgUxy-91DW8AnaTrc7nvDHUfWazi_0"
GEMINI_API_KEY = "AIzaSyDDwEucj4KNsnUT4m4qpt1pwnByhm6_vjM"

#Language Code Mapping
LANGUAGE_CODE_MAP = {
    "Hindi": "hi",
    "Tamil": "ta",
    "Telugu": "te",
    "Kannada": "kn",
    "Malayalam": "ml",
    "Bengali": "bn",
    "Gujarati": "gu",
    "Marathi": "mr",
}

# Global variable to store current audio file path
current_audio_path = None

# Global variables for quiz
current_quiz_data = None
user_answers = {}

#cleaning the text generated by gemini
def clean_text(text):
    # Remove Markdown-style headers, bold, bullets, and excess whitespace
    text = re.sub(r"[*#‚Ä¢]+", "", text)  # remove *, #, ‚Ä¢
    text = re.sub(r"\n{2,}", "\n", text)  # reduce multiple newlines to one
    text = re.sub(r"\s{2,}", " ", text)  # collapse multiple spaces
    return text.strip()

# Utility Functions
def scan_headline():
    cap = cv2.VideoCapture(0)
    while True:
        ret, frame = cap.read()
        if not ret or frame is None:
            break
        cv2.imwrite("captured_frame.jpg", frame)
        break
    cap.release()
    cv2.destroyAllWindows()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    reader = easyocr.Reader(['en'])
    results = reader.readtext(gray)
    if not results:
        return ""
    return " ".join([res[1] for res in results])

def extract_text_from_image(image_path):
    """Extract text from uploaded image file using OCR"""
    try:
        # Read the image
        image = cv2.imread(image_path)
        if image is None:
            return "‚ùå Could not read the image file. Please check the file format."
        
        # Convert to grayscale for better OCR results
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Initialize EasyOCR reader
        reader = easyocr.Reader(['en'])
        
        # Perform OCR
        results = reader.readtext(gray)
        
        if not results:
            return "‚ùå No text found in the image."
        
        # Extract and join all detected text
        extracted_text = " ".join([res[1] for res in results])
        return extracted_text
        
    except Exception as e:
        return f"‚ùå Error processing image: {str(e)}"

def get_video(query):
    model = SentenceTransformer("all-MiniLM-L6-v2")
    youtube = googleapiclient.discovery.build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
    search_response = youtube.search().list(q=query, part="snippet", maxResults=10, type="video").execute()

    videos = [{
        "title": item["snippet"]["title"],
        "description": item["snippet"]["description"],
        "url": f"https://www.youtube.com/watch?v={item['id']['videoId']}"
    } for item in search_response.get("items", [])]

    if not videos:
        return None

    query_emb = model.encode(query, convert_to_tensor=True).cpu().numpy()

    similarities = []
    for video in videos:
        title_emb = model.encode(video["title"], convert_to_tensor=True).cpu().numpy()
        desc_emb = model.encode(video["description"], convert_to_tensor=True).cpu().numpy()
        sim = (np.dot(query_emb, title_emb) + np.dot(query_emb, desc_emb)) / (
            np.linalg.norm(query_emb) * (np.linalg.norm(title_emb) + np.linalg.norm(desc_emb))
        )
        similarities.append(sim)

    best_index = np.argmax(similarities)
    return videos[best_index]["title"], videos[best_index]["url"]

def generate_notes_with_gemini(text):
    prompt = f"Generate study notes from the given topic:\n\n{text}"
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    response = requests.post(url, headers=headers, data=json.dumps(data))
    if response.status_code == 200:
        raw_notes = response.json()["candidates"][0]["content"]["parts"][0]["text"]
        return clean_text(raw_notes)
    else:
        return "‚ùå Error generating notes."

def generate_summary_with_gemini(text: str):
        API_KEY = GEMINI_API_KEY
        url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}"
        prompt = f"Summarize the following text in detail as refernce notes for a student:\n{text}"
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        headers = {'Content-Type': 'application/json'}
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            summary = response.json()["candidates"][0]["content"]["parts"][0]["text"]
            return clean_text(summary)
        else:
            return "Error generating summary"

def summarize_video(text):
    result = get_video(text)
    if result is None:
        return "No video found"
    _, video_url = result
    audio_path = download_audio(video_url)
    raw_transcript = transcribe_audio(audio_path)
    return generate_summary_with_gemini(raw_transcript)  

def download_audio(video_url):
    ffmpeg_path = "C:/ffmpeg/ffmpeg-7.1.1-essentials_build/bin"
    ydl_opts = {
        'ffmpeg_location': ffmpeg_path,
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192'
        }],
        'no_part': True,
        'force_overwrites': True
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(video_url, download=True)
        return ydl.prepare_filename(info).rsplit(".", 1)[0] + ".mp3"

def transcribe_audio(audio_path):
    model = WhisperModel("base")
    segments, _ = model.transcribe(audio_path)
    return " ".join([segment.text for segment in segments])

def translate_text(text, lang_name, retries=3):
    lang_code = LANGUAGE_CODE_MAP.get(lang_name, "hi")
    max_chunk_size = 5000

    def split_text(text, size):
        return [text[i:i+size] for i in range(0, len(text), size)]

    chunks = split_text(text, max_chunk_size)
    translated = []

    for chunk in chunks:
        for attempt in range(retries):
            try:
                translated_chunk = GoogleTranslator(source="auto", target=lang_code).translate(chunk)
                translated.append(translated_chunk)
                break  # Success
            except dt_exceptions.RequestError:
                if attempt < retries - 1:
                    time.sleep(1)  # wait and retry
                else:
                    return f"‚ùå Failed to translate after {retries} attempts. Check your internet connection."
            except Exception as e:
                return f"‚ùå Unexpected error: {e}"
    return clean_text("\n".join(translated))

def generate_audio(text, lang_name):
    """Generate audio file and return the file path"""
    global current_audio_path
    
    if not text or not text.strip():
        return None, "‚ùå No text provided for audio generation"
    
    lang_code = LANGUAGE_CODE_MAP.get(lang_name, "en")
    
    try:
        # Create a temporary file
        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_file:
            audio_path = temp_file.name
        
        tts = gTTS(text=text, lang=lang_code)
        tts.save(audio_path)
        current_audio_path = audio_path
        return audio_path, "‚úÖ Audio generated successfully!"
        
    except Exception as e:
        return None, f"‚ùå Audio generation error: {str(e)}"

def play_audio():
    """Play audio with pygame"""
    global current_audio_path
    try:
        if current_audio_path and os.path.exists(current_audio_path):
            if pygame.mixer.music.get_busy():
                pygame.mixer.music.stop()
            pygame.mixer.music.load(current_audio_path)
            pygame.mixer.music.play()
            return "üîä Audio playing..."
        else:
            return "‚ùå No audio file available to play"
    except Exception as e:
        return f"‚ùå Playback error: {str(e)}"

def pause_audio():
    """Pause audio playback"""
    try:
        if pygame.mixer.music.get_busy():
            pygame.mixer.music.pause()
            return "‚è∏Ô∏è Audio paused"
        else:
            return "‚ùå No audio currently playing"
    except Exception as e:
        return f"‚ùå Pause error: {str(e)}"

def resume_audio():
    """Resume audio playback"""
    try:
        pygame.mixer.music.unpause()
        return "‚ñ∂Ô∏è Audio resumed"
    except Exception as e:
        return f"‚ùå Resume error: {str(e)}"

def stop_audio():
    """Stop audio playback"""
    try:
        pygame.mixer.music.stop()
        return "‚èπÔ∏è Audio stopped"
    except Exception as e:
        return f"‚ùå Stop error: {str(e)}"

def get_text_for_audio(english_text, translated_text, language):
    """Determine which text to use for audio generation"""
    if language == "English" or not translated_text or translated_text.strip() == "":
        return english_text
    return translated_text

# MODIFIED QUIZ GENERATION FUNCTIONS
def generate_quiz_questions_with_gemini(text, num_questions=10):
    """Generate quiz questions using Gemini API"""
    prompt = f"""Generate {num_questions} multiple choice questions based on the following topic: {text}

For each question, provide:
1. The question text
2. Four answer options (A, B, C, D)
3. The correct answer (A, B, C, or D)
4. A brief explanation of why the answer is correct

Format the output as JSON with the following structure:
{{
  "questions": [
    {{
      "question": "Question text here?",
      "options": {{
        "A": "Option A text",
        "B": "Option B text", 
        "C": "Option C text",
        "D": "Option D text"
      }},
      "correct_answer": "A",
      "explanation": "Explanation text here"
    }}
  ]
}}

Make sure the questions are educational and test understanding of the key concepts."""

    data = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        if response.status_code == 200:
            raw_response = response.json()["candidates"][0]["content"]["parts"][0]["text"]
            
            # Clean the response to extract JSON
            json_start = raw_response.find('{')
            json_end = raw_response.rfind('}') + 1
            
            if json_start != -1 and json_end != -1:
                json_str = raw_response[json_start:json_end]
                quiz_data = json.loads(json_str)
                return quiz_data
            else:
                return {"error": "Failed to parse quiz questions from response"}
        else:
            return {"error": f"API request failed with status {response.status_code}"}
    except json.JSONDecodeError:
        return {"error": "Failed to parse JSON response from Gemini"}
    except Exception as e:
        return {"error": f"Error generating quiz: {str(e)}"}

def generate_quiz_interface(topic, num_questions):
    """Generate quiz and return Gradio components"""
    global current_quiz_data, user_answers
    
    if not topic or not topic.strip():
        return [gr.update(visible=False)] * 20  # Hide all quiz components
    
    try:
        num_q = int(num_questions) if num_questions else 10
        quiz_data = generate_quiz_questions_with_gemini(topic, num_q)
        
        if "error" in quiz_data:
            return [gr.update(visible=False)] * 20  # Hide all components on error
        
        current_quiz_data = quiz_data
        user_answers = {}
        
        questions = quiz_data.get("questions", [])
        updates = []
        
        # Generate updates for each question component (up to 10 questions)
        for i in range(10):
            if i < len(questions):
                q = questions[i]
                question_text = f"**Question {i+1}:** {q['question']}"
                options = [f"{key}. {value}" for key, value in q['options'].items()]
                
                updates.extend([
                    gr.update(value=question_text, visible=True),  # Question text
                    gr.update(choices=options, value=None, visible=True)  # Radio options
                ])
            else:
                updates.extend([
                    gr.update(visible=False),  # Hide question
                    gr.update(visible=False)   # Hide options
                ])
        
        return updates
        
    except Exception as e:
        return [gr.update(visible=False)] * 20  # Hide all components on error

def submit_quiz(*answers):
    """Submit quiz and calculate score"""
    global current_quiz_data, user_answers
    
    if not current_quiz_data:
        return "‚ùå No quiz data available"
    
    questions = current_quiz_data.get("questions", [])
    score = 0
    total = len(questions)
    results = []
    
    for i, answer in enumerate(answers[:total]):
        if i < len(questions):
            q = questions[i]
            correct_answer = q['correct_answer']
            
            # Extract selected option letter (A, B, C, D)
            selected_option = None
            if answer:
                selected_option = answer[0]  # First character should be the option letter
            
            is_correct = selected_option == correct_answer
            if is_correct:
                score += 1
            
            results.append(f"""
**Question {i+1}:** {q['question']}
**Your Answer:** {answer if answer else 'Not answered'}
**Correct Answer:** {correct_answer}. {q['options'][correct_answer]}
**Explanation:** {q['explanation']}
**Status:** {'‚úÖ Correct' if is_correct else '‚ùå Incorrect'}
""")
    
    result_text = f"""
# üéØ Quiz Results

**Score: {score}/{total} ({(score/total)*100:.1f}%)**

---

{''.join(results)}
"""
    
    return result_text

# UI Functions
def ui_scan_headline():
    """Original webcam scanning function"""
    #return scan_headline()
    return "Computer Networks"

def ui_upload_and_extract(uploaded_file):
    """Handle uploaded file and extract text"""
    if uploaded_file is None:
        return "‚ùå No file uploaded. Please upload an image file."
    
    try:
        # Get the file path from the uploaded file
        file_path = uploaded_file.name
        
        # Extract text from the uploaded image
        extracted_text = extract_text_from_image(file_path)
        
        return extracted_text
        
    except Exception as e:
        return f"‚ùå Error processing uploaded file: {str(e)}"

def ui_watch_video(text):
    result = get_video(text)
    if result is None:
        return "No video found", ""
    title, url = result
    webbrowser.open(url)
    return title, url

def ui_summarize_video(text):
    return summarize_video(text)

def ui_translate_summary(english_text, target_language):
    return translate_text(english_text, target_language)

def ui_generate_audio_summary(english_text, translated_text, language):
    """Generate audio for summary"""
    text_to_speak = get_text_for_audio(english_text, translated_text, language)
    if not text_to_speak:
        return "‚ùå No text available to generate audio"
    
    audio_path, message = generate_audio(text_to_speak, language)
    return message

def ui_generate_audio_notes(english_text, translated_text, language):
    """Generate audio for notes"""
    text_to_speak = get_text_for_audio(english_text, translated_text, language)
    if not text_to_speak:
        return "‚ùå No text available to generate audio"
    
    audio_path, message = generate_audio(text_to_speak, language)
    return message

def conditional_translate_summary(text, lang):
    return text if lang == "English" else translate_text(text, lang)

def conditional_translate_notes(text, lang):
    return text if lang == "English" else translate_text(text, lang)

# File saving functions
def save_text_to_file(text, filename):
    if text:
        with open(filename, "w", encoding="utf-8") as f:
            f.write(text)
        return filename
    return None

# Gradio UI
custom_css = """
body {
    background-image: url('webbg.png'); 
    background-size: cover;
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}
h1 {
    text-align: center; 
    color: #000000; 
    background-color: #FFFDD0; 
    padding: 20px;
    border-radius: 15px;
    font-size: 2.2rem;
}
.gr-button {
    font-size: 16px;
    font-weight: 600;
    background-color: #add8e6 !important;
    color: white !important;
    border: none !important;
    border-radius: 8px !important;
    padding: 10px 20px;
}
.or-divider {
    text-align: center;
    font-size: 18px;
    font-weight: 600;
    color: #666;
    margin: 15px 0;
    position: relative;
}
.or-divider::before,
.or-divider::after {
    content: '';
    position: absolute;
    top: 50%;
    width: 45%;
    height: 1px;
    background-color: #ccc;
}
.or-divider::before {
    left: 0;
}
.or-divider::after {
    right: 0;
}
"""

with gr.Blocks(css=custom_css) as demo:
    gr.Markdown("<h1>üì∞ Text to Learning Assistant</h1>")

    gr.Markdown("## üì∑ Text Input Options")
    
    # Webcam scan button on top
    btn_scan = gr.Button("üì∑ Scan with Webcam", variant="primary", size="lg")
    
    # OR divider
    gr.HTML('<div class="or-divider">OR</div>')
    
    # File upload section below
    file_upload = gr.File(
        label="", 
        file_types=["image"], 
        type="filepath",
        show_label=False
    )
    btn_extract = gr.Button("üîç Extract Text from Upload", variant="secondary")
    
    output_text = gr.Textbox(label="üìÑ Extracted Text", interactive=True, lines=3)

    gr.Markdown("## ‚û°Ô∏è What would you like to do?")

    with gr.Accordion("‚ñ∂Ô∏è Option 1: Find and Summarize YouTube Video", open=False):
        with gr.Row():
            btn_watch = gr.Button("üîç Find Best Video")
            btn_summary = gr.Button("üìÑ Generate Summary")
        video_title = gr.Textbox(label="üéûÔ∏è Video Title", interactive=False)
        video_url = gr.Textbox(label="üîó Video URL", interactive=False)

        english_summary = gr.Textbox(label="üìù English Summary", interactive=False)
        language_selector_summary = gr.Dropdown(
            choices=["English", "Hindi", "Tamil", "Telugu", "Kannada", "Malayalam", "Bengali", "Gujarati", "Marathi"],
            label="üåê Translate Summary To",
            value="English"
        )
        translated_summary = gr.Textbox(label="üåç Translated Summary", interactive=False)
        
        # Audio Controls for Summary
        with gr.Row():
            btn_generate_audio_summary = gr.Button("üîä Generate Audio")
            btn_play_summary = gr.Button("‚ñ∂Ô∏è Play")
            btn_pause_summary = gr.Button("‚è∏Ô∏è Pause")
            btn_resume_summary = gr.Button("üîÑ Resume")
            btn_stop_summary = gr.Button("‚èπÔ∏è Stop")
        
        audio_status_summary = gr.Textbox(label="üéµ Audio Status", interactive=False)

    with gr.Accordion("üßæ Option 2: Generate Notes from Extracted Text", open=False):
        with gr.Row():
            btn_notes = gr.Button("üìò Generate Study Notes")
        notes_english = gr.Textbox(label="üìë Notes in English", interactive=False)
        language_selector_notes = gr.Dropdown(
            choices=["English", "Hindi", "Tamil", "Telugu", "Kannada", "Malayalam", "Bengali", "Gujarati", "Marathi"],
            label="üåê Translate Notes To",
            value="English"
        )
        notes_translated = gr.Textbox(label="üåç Translated Notes", interactive=False)
        
        # Audio Controls for Notes
        with gr.Row():
            btn_generate_audio_notes = gr.Button("üîä Generate Audio")
            btn_play_notes = gr.Button("‚ñ∂Ô∏è Play")
            btn_pause_notes = gr.Button("‚è∏Ô∏è Pause")
            btn_resume_notes = gr.Button("üîÑ Resume")
            btn_stop_notes = gr.Button("‚èπÔ∏è Stop")
    
        audio_status_notes = gr.Textbox(label="üéµ Audio Status", interactive=False)

    # MODIFIED QUIZ SECTION - Interactive Quiz in Gradio
    with gr.Accordion("üß© Option 3: Interactive Quiz", open=False):
        with gr.Row():
            quiz_num_questions = gr.Dropdown(
                choices=["5", "10"],
                label="üìä Number of Questions",
                value="5"
            )
            btn_generate_quiz = gr.Button("üß© Generate Quiz")
        
        # Quiz Questions (up to 10 questions)
        quiz_components = []
        quiz_radios = []
        
        for i in range(10):
            question_md = gr.Markdown(visible=False)
            question_radio = gr.Radio(visible=False, label="Select your answer:")
            quiz_components.extend([question_md, question_radio])
            quiz_radios.append(question_radio)
        
        btn_submit_quiz = gr.Button("üìù Submit Quiz", visible=False)
        quiz_results = gr.Markdown(visible=False, label="Quiz Results")

    # File Downloads
    download_notes = gr.File(label="üì• Download Notes")
    download_summary = gr.File(label="üì• Download Summary")

    # Button Logic
    btn_scan.click(fn=ui_scan_headline, outputs=output_text)
    
    # File upload logic
    btn_extract.click(fn=ui_upload_and_extract, inputs=file_upload, outputs=output_text)

    btn_watch.click(fn=ui_watch_video, inputs=output_text, outputs=[video_title, video_url])
    btn_summary.click(fn=ui_summarize_video, inputs=output_text, outputs=english_summary)

    # Translation logic
    language_selector_summary.change(
        fn=conditional_translate_summary, 
        inputs=[english_summary, language_selector_summary], 
        outputs=translated_summary
    )

    # Summary Audio Controls
    btn_generate_audio_summary.click(
        fn=ui_generate_audio_summary,
        inputs=[english_summary, translated_summary, language_selector_summary],
        outputs=audio_status_summary
    )
    
    btn_play_summary.click(fn=play_audio, outputs=audio_status_summary)
    btn_pause_summary.click(fn=pause_audio, outputs=audio_status_summary)
    btn_resume_summary.click(fn=resume_audio, outputs=audio_status_summary)
    btn_stop_summary.click(fn=stop_audio, outputs=audio_status_summary)

    # Notes generation and translation
    btn_notes.click(fn=generate_notes_with_gemini, inputs=output_text, outputs=notes_english)
    
    language_selector_notes.change(
        fn=conditional_translate_notes, 
        inputs=[notes_english, language_selector_notes], 
        outputs=notes_translated
    )

    # Notes Audio Controls
    btn_generate_audio_notes.click(
        fn=ui_generate_audio_notes,
        inputs=[notes_english, notes_translated, language_selector_notes],
        outputs=audio_status_notes
    )
    
    btn_play_notes.click(fn=play_audio, outputs=audio_status_notes)
    btn_pause_notes.click(fn=pause_audio, outputs=audio_status_notes)
    btn_resume_notes.click(fn=resume_audio, outputs=audio_status_notes)
    btn_stop_notes.click(fn=stop_audio, outputs=audio_status_notes)

    # MODIFIED QUIZ BUTTON LOGIC
    def show_quiz_interface(topic, num_questions):
        updates = generate_quiz_interface(topic, num_questions)
        # Show submit button and results area if quiz was generated successfully
        if any(update.get('visible', False) for update in updates if hasattr(update, 'get')):
            updates.extend([
                gr.update(visible=True),   # Submit button
                gr.update(visible=False)   # Results (hidden initially)
            ])
        else:
            updates.extend([
                gr.update(visible=False),  # Submit button
                gr.update(visible=False)   # Results
            ])
        return updates

    btn_generate_quiz.click(
        fn=show_quiz_interface,
        inputs=[output_text, quiz_num_questions],
        outputs=quiz_components + [btn_submit_quiz, quiz_results]
    )

    # Submit quiz logic
    btn_submit_quiz.click(
        fn=lambda *args: [submit_quiz(*args), gr.update(visible=True)],
        inputs=quiz_radios,
        outputs=[quiz_results, quiz_results]
    )

    # File Saving
    notes_english.change(
        fn=lambda text: save_text_to_file(text, "notes.txt"), 
        inputs=notes_english, 
        outputs=download_notes
    )
    english_summary.change(
        fn=lambda text: save_text_to_file(text, "summary.txt"), 
        inputs=english_summary, 
        outputs=download_summary
    )

    demo.launch(share=True)